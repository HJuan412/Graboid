#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Nov 30 11:06:10 2021

@author: hernan
"""

import sys
sys.path.append('preprocess')
sys.path.append('classif')
#%% libraries
import concurrent.futures
import logging
import numba as nb
import numpy as np
import os
import pandas as pd
import pickle
import time
from classification import classification
from classification import cost_matrix
from DATA import DATA
from glob import glob
from preprocess import feature_selection as fsele
from preprocess import windows

#%% set
logger = logging.getLogger('Graboid.calibrator')
logger.setLevel(logging.DEBUG)

#%% functions
def make_dirs(base_dir):
    os.makedirs(f'{base_dir}/data', exist_ok=bool)
    os.makedirs(f'{base_dir}/warnings', exist_ok=bool)

def get_metrics(confusion, taxons):
    # get calibration metrics for a given confusion matrix
    # confusion: confusion matrix
    # taxons: taxon index (generated by build_confusion)

    results = []
    for idx, tax in enumerate(taxons):
        # get true/false positives/negatives for each taxon
        tp = confusion[idx, idx]
        tn = np.delete(np.delete(confusion, idx, axis=0), idx, axis=1).sum()
        fp = np.delete(confusion[idx], idx).sum()
        fn = np.delete(confusion[:, idx], idx).sum()
        
        # calculate metrics (accuracy, precision, recall and F1)
        acc = (tp + tn) / (tp + tn + fp + fn)
        prc = 0
        rec = 0
        f1 = 0
        if tp > 0:
            # if there are no positive values, prec, rec and f1 are 0 by default
            prc = tp / (tp + fp)
            rec = tp / (tp + fn)
            f1 = (2 * prc * rec)/(prc + rec)
        
        results.append([tax, acc, prc, rec, f1])
    return results

def loo_generator(nrecs):
    # generates the indexes for the training dataset and the testing instance in leave-one-out calibration
    record_idxs = np.arange(nrecs)
    for idx in record_idxs:
        train_idx = np.delete(record_idxs, idx)
        test_idx = idx
        yield train_idx, test_idx

@nb.njit
def build_confusion(pred, real):
    # build the confusion matrix (for a given RANK)
    # pred: array of PREDICTED taxon for each training sample
    # pred: array of REAL taxon for each training sample

    # list & count taxes
    uniq_taxes = np.unique(real)
    n_taxes = len(uniq_taxes)
    
    confusion = np.zeros((n_taxes, n_taxes), dtype=np.int32)
    # rows: REAL taxons
    # columns: PREDICTED taxons
    
    for idx_0, tax_0 in enumerate(uniq_taxes):
        tax_pred = pred[real == tax_0]
        for idx_1, tax_1 in enumerate(uniq_taxes):
            pred_as = len(tax_pred[tax_pred == tax_1])
            confusion[idx_0, idx_1] = pred_as
    return confusion, uniq_taxes
    
def build_cal_tab(pred_tax, real_tax, n_ranks=6):
    # build the calibration table from the given results
    # n_ranks 6 by default (phylum, class, order, family, genus, species), could be modifyed to include less/more (should be done automatically)
    
    results = []
    # remove first(query name) and last (K) columns from predicted taxons
    pred_cropped = pred_tax[:,1:-1].T
    real_mat = real_tax.to_numpy().T
    ranks = real_tax.columns
    
    for rank, pred, real in zip(ranks, pred_cropped, real_mat):
        # build a confusion matrix and get results from there, update results table
        rank_confusion, taxons = build_confusion(pred, real)
        rank_metrics = get_metrics(rank_confusion, taxons)
        rank_metrics = np.insert(rank_metrics, 0, rank, axis=1)
        results.append(rank_metrics)
    return np.concatenate(results)

    for rank in np.arange(n_ranks):
        # build a confusion matrix and get results from there, update results table
        rank_confusion, taxons = build_confusion(pred_cropped[:,rank], real_tax.iloc[:,rank].to_numpy())
        rank_metrics = get_metrics(rank_confusion, taxons)
        rank_metrics = np.insert(rank_metrics, 0, rank, axis=1)
        results.append(rank_metrics)
    return np.concatenate(results)

#%% classes
class Calibrator:
    def __init__(self, out_dir, warn_dir):
        self.out_dir = out_dir
        self.warn_dir = warn_dir
        
        self.selector = fsele.Selector(out_dir)
        self.loader = None
        self.set_row_thresh()
        self.set_col_thresh()
        self.set_min_seqs()
        self.set_rank()
        self.set_dist_mat('id')
        self.report = None
    
    @property
    def row_thresh(self):
        return self.__row_thresh
    @row_thresh.setter
    def row_thresh(self, row_thresh):
        self.__row_thresh = max(0., min(1., row_thresh))
    @property
    def col_thresh(self):
        return self.__col_trhesh
    @col_thresh.setter
    def col_thresh(self, col_thresh):
        self.__col_thresh = max(0., min(1., col_thresh))
    @property
    def min_seqs(self):
        return self.__min_seqs
    @min_seqs.setter
    def min_seqs(self, min_seqs):
        self.__min_seqs = max(0, min_seqs)
    
    @property
    def dist_mat(self):
        return self.__dist_mat
    @dist_mat.setter
    def dist_mat(self, mat_code):
        try:
            self.__dist_mat = cost_matrix(mat_code)
        except:
            raise
            
    def set_database(self, database):
        if not database in DATA.DBASES:
            print(f'Database {database} not found.')
            print('Current databases include:')
            for db, desc in DATA.DBASE_LIST.items():
                print(f'\tDatabase: {db} \t:\t{desc}')
            raise Exception('Database not found')
        self.db_dir = DATA.DATAPATH + '/' + database
        
        mat_file = glob(self.db_dir + '/*__map.npz')[0]
        tax_file = glob(self.db_dir + '/*.tax')[0]
        acc_file = glob(self.db_dir + '/*__map.accs')[0]
        order_file = self.db_dir + '/order.npz'
        diff_file = self.db_dir + 'diff.csv'
        
        # set the loader with the learning data
        self.loader = windows.WindowLoader('Graboid.calibrator.windowloader')
        self.loader.set_files(mat_file, acc_file, tax_file)
        # load information files
        self.selector.load_order_mat(order_file)
        self.selector.load_diff_tab(diff_file)
    
    def check_ready(self):
        # check that the calibration is ready to go
        missing = []
        try:
            self.cost_mat
        except AttributeError:
            missing.append('distance matrix')
        try:
            self.loader.matrix
            self.loader.bounds
            self.loader.dims
        except AttributeError:
            missing.append('alignment matrix')
        try:
            self.loader.accdist
        except AttributeError:
            missing.append('accession list')
        try:
            self.loader.tax_tab            
        except AttributeError:
            missing.append('taxonomy table')
        try:
            self.order_file
        except AttributeError:
            missing.append('order file')
        ready = len(missing) > 0
        return ready, missing
    
    def grid_search(self, w_size, w_step, max_k, step_k, max_n, step_n, min_k=1, min_n=5, filename=None, threads=1, keep_classif=False):
        if self.loader is None:
            return
        
        # prepare out files
        if filename is None:
            filename = time.strftime("report_%d%m%Y-%H%M%S")
        self.out_file = f'{self.out_dir}/{filename}.csv'
        self.classif_file = f'{self.out_dir}/classif_{filename}.csv'
        self.meta_file = f'{self.out_dir}/{filename}.meta'
        header = True # toggle this when a report file hasn't been generated yet, use to control inclusion of header col
        
        # set calibration parameters
        # set coordinate ranges for the sliding window
        max_pos = self.loader.dims[1]
        start_range = np.arange(0, max_pos - w_size, w_step)
        if start_range[-1] < max_pos - w_size:
            # add a tail window, if needed, to cover the entire sequence
            np.append(start_range, max_pos - w_size)
        end_range = start_range + w_size
        w_coords = np.array([start_range, end_range]).T
        
        # k & n ranges
        k_range = np.arange(min_k, max_k, step_k)
        n_range = np.arange(min_n, max_n, step_n)
        
        # begin calibration
        for idx, (start, end) in enumerate(w_coords):
            t0 = time.time()
            print(f'Window {start} - {end} ({idx + 1} of {len(w_coords)})')
            # extract window and select atributes
            window = self.loader.get_window(start, end, self.row_thresh, self.col_thresh)
            if len(window.eff_mat) == 0:
                continue
            n_seqs = window.eff_mat.shape[0]
            if n_seqs < self.min_seqs:
                # not enough sequences passed the filter, skip iteration
                print(f'Window {start} - {end}. Not enoug sequences to perform calibration ({n_seqs}, min = {self.min_seqs}), skipping')
                continue
            # n_sites = self.selector.get_sites(n_range, start, end, self.rank)
            n_sites = self.selector.get_sites(n_range, self.rank, window.cols)
            y = window.eff_tax
            # distance container, 3d array, paired distance matrix for every value of n
            dist_mat = np.zeros((n_seqs, n_seqs, len(n_range)), dtype=np.float32)
            # get paired distances
            t1 = time.time()
            logger.debug(f'prep time {t1 - t0}')
            for idx_0 in np.arange(n_seqs - 1):
                qry_seq = window.eff_mat[[idx_0]]
                idx_1 = idx_0 + 1
                ref_seqs = window.eff_mat[idx_1:]
                # persistent distance array, updates with each value of n
                dists = np.zeros((1, ref_seqs.shape[0]), dtype=np.float32)
                for n_idx, sites in enumerate(n_sites.values()):
                    sub_qry = qry_seq[:, sites]
                    sub_ref = ref_seqs[:, sites]
                    dists += classification.get_dists(sub_qry, sub_ref, self.cost_mat).reshape(1, -1)
                    dist_mat[idx_0, idx_1:, n_idx] = dists
                    dist_mat[idx_1:, idx_0, n_idx] = dists
            t2 = time.time()
            logger.debug(f'dist calculation {t2 - t1}')
            # get ordered_neighbours and sorted distances (excluding first columns, which corresponds to the diagonal)
            neighbours = np.argsort(dist_mat, axis=1)[:,1:,:]
            ordered_dists = [dist_mat[np.tile(np.arange(n_seqs), (n_seqs-1, 1)).T, neighbours[...,n], n] for n in range(neighbours.shape[2])]
            
            guide = [(n, mode, classif) for mode, classif in classification.classif_funcs_nb.items() for n in range(len(n_range))]
            classif_report = []
            # use multiprocessing to speed up classification
            t3 = time.time()
            with concurrent.futures.ProcessPoolExecutor(max_workers=threads) as executor:
                # since we're using numba functions, y must be cast as a numpy array
                future_classifs = {executor.submit(classifier, neighbours[...,n], ordered_dists[n], y.to_numpy(), k_range):(mode,n) for (n, mode, classifier) in guide}
                for future in concurrent.futures.as_completed(future_classifs):
                    (pre_classif, columns) = future.result()
                    (mode, n) = future_classifs[future]
                    classif = classification.get_classif(pre_classif, classification.classif_modes[mode])
                    mode_report = pd.DataFrame(classif, columns=columns)
                    mode_report['mode'] = mode
                    mode_report['n'] = n_range[n]
                    classif_report.append(mode_report)
            classif_report = pd.concat(classif_report)
            t4 = time.time()
            logger.debug(f'classification {t4 - t3}')
            # store intermediate classification results (if enabled)
            if keep_classif:
                classif_report['w_start'] = start
                classif_report['w_end'] = end
                classif_report.to_csv(self.classif_file, header=header, index=False, mode='a')
            # get classification metrics
            t5 = time.time()
            for (k, n, mode), subtab in classif_report.groupby(['_k', 'n', 'mode']):
                for rk, rk_subtab in subtab.groupby('rk'):
                    pred = rk_subtab.tax.values
                    real = y.loc[rk_subtab.idx.values].iloc[:,int(rk)].values
                    confusion, taxons = build_confusion(pred, real)
                    metrics = get_metrics(confusion, taxons)
                    metrics_report = pd.DataFrame(metrics, columns=['Taxon', 'Accuracy', 'Precision', 'Recall', 'F1_score'])
                    metrics_report['w_start'] = start
                    metrics_report['w_end'] = end
                    metrics_report['rank'] = rk
                    metrics_report['n_sites'] = n
                    metrics_report['K'] = k
                    metrics_report['mode'] = classification.classif_longnames[mode]
                    
                    metrics_report.to_csv(self.out_file, header=header, index=False, mode='a')
                    header = False
            t6 = time.time()
            logger.debug(f'metric calculation {t6 - t5}')
            
            self.meta = {'k':k_range,
                         'n':n_range,
                         'w_size':w_size,
                         'w_step':w_step}
            with open(self.meta_file, 'wb') as meta_handle:
                pickle.dump(self.meta, meta_handle)

    def save_report(self, filename=None):
        if filename is None:
            filename = time.strftime("report_%d%m%Y-%H%M%S")
        self.out_file = f'{self.out_dir}/{filename}.csv'
        self.meta_file = f'{self.out_dir}/{filename}.meta'
        if not self.report is None:
            self.report.to_csv(self.out_file)
            with open(self.meta_file, 'wb') as meta_handle:
                pickle.dump(self.meta, meta_handle)
            logger.info(f'Calibration report saved to {self.out_file}')